{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "haar=cv2.CascadeClassifier(\"haarcascade_frontalface_alt.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.mkdir(\"faces\\\\train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter name : shubham\n",
      "already exist\n"
     ]
    }
   ],
   "source": [
    "a=input(\"enter name : \")\n",
    "try:\n",
    "    import os\n",
    "    os.mkdir('C:\\\\Users\\\\shubham\\\\faces\\\\train\\\\'+a)\n",
    "    os.mkdir('C:\\\\Users\\\\shubham\\\\faces\\\\test\\\\'+a)\n",
    "    \n",
    "    video=cv2.VideoCapture(0)\n",
    "    j=1\n",
    "    count=1\n",
    "    while count<51:\n",
    "        ret,frame1=video.read()\n",
    "        faces =haar.detectMultiScale(frame1, scaleFactor=1.1,minNeighbors=5)\n",
    "        human=1\n",
    "        for(x,y,w,h) in faces:\n",
    "            cv2.rectangle(frame1,(x,y),(x+w,y+h),(250,0,0),10)\n",
    "            cv2.putText(frame1,\"p\"+str(human),(x-10,y-10),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),5)\n",
    "            human+=1\n",
    "        cv2.imshow(\"video capture\",frame1)\n",
    "        cv2.waitKey(1)\n",
    "        l=len(faces)\n",
    "        for i in range(l):\n",
    "                y,x,w,h=faces[i][0],faces[i][1],faces[i][2],faces[i][3]\n",
    "                crop=frame1[x:x+h,y:y+w]\n",
    "                if count<15:\n",
    "                    cv2.imshow(\"face\",crop)\n",
    "                    cv2.waitKey(1)\n",
    "                    cv2.imwrite('C:\\\\Users\\\\shubham\\\\faces\\\\test\\\\'+a+'/'+str(a)+str(j)+\".jpg\",crop)\n",
    "                    count+=1\n",
    "                else :\n",
    "                    cv2.imshow(\"face\",crop)\n",
    "                    cv2.waitKey(1)\n",
    "                    cv2.imwrite('C:\\\\Users\\\\shubham\\\\faces\\\\train\\\\'+a+'/'+str(a)+str(j)+\".jpg\",crop)\n",
    "                    count+=1\n",
    "                    \n",
    "                #cv2.putText(crop,\"p\"+str(human),(x-10,y-10),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),5)\n",
    "            #human+=1\n",
    "                j=j+1\n",
    "         \n",
    "    video.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "except :\n",
    "    print(\"already exist\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=[]\n",
    "for file in os.listdir(\"faces\\\\train\"):\n",
    "    label.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'akanksha jangid',\n",
       " 1: 'Osheen',\n",
       " 2: 'piyush',\n",
       " 3: 'ronish',\n",
       " 4: 'sahil',\n",
       " 5: 'sanket',\n",
       " 6: 'sarvagya',\n",
       " 7: 'satyam',\n",
       " 8: 'utkarsh'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d={}\n",
    "for i in range(len(label)):\n",
    "    d[i]=label[i]\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\anaconda\\envs\\opencv-env\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Conv2D(32,(5,5),input_shape=(64,64,3),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Conv2D(64,(5,5),activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=800,activation='relu'))\n",
    "classifier.add(Dense(units=400,activation='relu'))\n",
    "classifier.add(Dense(units=len(label),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set=train_datagen.flow_from_directory(\n",
    "    'faces\\\\train',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')\n",
    "#len(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 126 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set=train_datagen.flow_from_directory(\n",
    "    'faces\\\\test',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\anaconda\\envs\\opencv-env\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2\n",
      "216/216 [==============================] - 193s 895ms/step - loss: 0.2111 - acc: 0.9239 - val_loss: 0.6689 - val_acc: 0.8923\n",
      "Epoch 2/2\n",
      "216/216 [==============================] - 172s 797ms/step - loss: 8.0501e-05 - acc: 1.0000 - val_loss: 0.6497 - val_acc: 0.8991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x234a79f9198>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=216,\n",
    "        epochs=2,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('model4_categorical_complex.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "a=load_model('model4_categorical_complex.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "from keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = image.load_img('faces\\\\test\\\\Osheen\\\\Osheen1.jpg',target_size = (64, 64)) #\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "#plt.figure(1)\n",
    "plt.imshow(test_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Osheen': 0,\n",
       " 'akanksha jangid': 1,\n",
       " 'piyush': 2,\n",
       " 'ronish': 3,\n",
       " 'sahil': 4,\n",
       " 'sanket': 5,\n",
       " 'sarvagya': 6,\n",
       " 'satyam': 7,\n",
       " 'utkarsh': 8}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)\n",
    "test_image = n.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=result.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sahil\n"
     ]
    }
   ],
   "source": [
    "s=train_set.class_indices\n",
    "name=[]\n",
    "for i in s:\n",
    "    name.append(i)\n",
    "for i in range(len(s)):\n",
    "    if i==a:\n",
    "        q=name[i]\n",
    "        print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(path):\n",
    "    test_image = image.load_img(path,target_size = (64, 64)) #\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = n.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "    a=result.argmax()\n",
    "    s=train_set.class_indices\n",
    "    name=[]\n",
    "    for i in s:\n",
    "        name.append(i)\n",
    "    for i in range(len(s)):\n",
    "        if i==a:\n",
    "            q=name[i]\n",
    "    return(q)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video=cv2.VideoCapture(0)\n",
    "y=None\n",
    "while True:\n",
    "    ret,frame1=video.read()\n",
    "    faces =haar.detectMultiScale(frame1, scaleFactor=1.1,minNeighbors=5)\n",
    "    \n",
    "    if cv2.waitKey(20) & 0xff == 32:\n",
    "        break\n",
    "    for (x,y,w,h) in faces:\n",
    "        w_rm=int(0.2*w/2)\n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(250,0,0),10)\n",
    "        path='faces\\\\a.jpg'\n",
    "        crop=frame1[y:y+h,x+w_rm:x+w-w_rm]\n",
    "        cv2.imwrite(path,crop)\n",
    "        \n",
    "        name1= predictor(path)\n",
    "        cv2.putText(frame1,name1,(x-10,y-10),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),5)\n",
    "    cv2.imshow('detector',frame1)\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=input(\"enter name\")\n",
    "haar=cv2.CascadeClassifier(\"G://programs//New Folder//haarcascade_frontalface_alt.xml\")\n",
    "import os\n",
    "os.mkdir('faces\\\\train\\\\'+a)\n",
    "os.mkdir('faces\\\\test\\\\'+a)\n",
    "\n",
    "video=cv2.VideoCapture(0)\n",
    "j=1\n",
    "count=1\n",
    "while count<51:\n",
    "    ret,frame1=video.read()\n",
    "    faces =haar.detectMultiScale(frame1, scaleFactor=1.1,minNeighbors=5)\n",
    "    human=1\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame1,(x,y),(x+w,y+h),(250,0,0),10)\n",
    "        cv2.putText(frame1,\"p\"+str(human),(x-10,y-10),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),5)\n",
    "        human+=1\n",
    "    cv2.imshow(\"video capture\",frame1)\n",
    "    cv2.waitKey(1)\n",
    "    l=len(faces)\n",
    "    for i in range(l):\n",
    "            y,x,w,h=faces[i][0],faces[i][1],faces[i][2],faces[i][3]\n",
    "            crop=frame1[x:x+h,y:y+w]\n",
    "            if count<15:\n",
    "                cv2.imshow(\"face\",crop)\n",
    "                cv2.waitKey(1)\n",
    "                cv2.imwrite('faces\\\\test\\\\'+a+'/'+str(a)+str(j)+\".jpg\",crop)\n",
    "                count+=1\n",
    "            else :\n",
    "                cv2.imshow(\"face\",crop)\n",
    "                cv2.waitKey(1)\n",
    "                cv2.imwrite('faces\\\\train\\\\'+a+'/'+str(a)+str(j)+\".jpg\",crop)\n",
    "                count+=1\n",
    "\n",
    "            #cv2.putText(crop,\"p\"+str(human),(x-10,y-10),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,255,0),5)\n",
    "        #human+=1\n",
    "            j=j+1\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
